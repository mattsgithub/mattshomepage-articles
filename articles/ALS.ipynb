{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization is a common tool used in recommendation systems. In particular, an algorithm known as ALS (alternating least squares) is very popular. I explore its mathematical foundations and provide an implementation in the programming language Python. I then test how well it performs on the MovieLens dataset.\n",
    "\n",
    "The idea of matrix factorization starts with a user-item matrix $\\mathbf{R_{m \\times n}}$. Each row corresponds to one user and each column corresponds to one item. Each cell is the quantitative preference a user has for an item (e.g., a rating, number of times bought, etc.). In practice, most of these values are missing since a user only interacts with a small percentage of all items. The goal is then to predict these missing values. Then, we can sort these values per user in descending order and recommend the top $k$ items given the top $k$ items scores are above a given threshold (i.e., taking the top K doesn't make sense in an absolute sense if the filled-in values indicate the user has no preference for them)\n",
    "\n",
    "The benefit of matrix factorization, is that if patterns exist in the $\\mathbf{R_{m \\times n}}$ matrix, we'd like to automatically learn these patterns. Suppose the matrix is approximated as:\n",
    "\n",
    "$\\mathbf{R_{m \\times n}} \\approx \\mathbf{U_{m \\times k}} {\\mathbf{V_{n \\times k}}}^{\\text{T}}$.\n",
    "\n",
    "In order to have the $\\mathbf{V}$ matrix have its rows as items, just like how the rows of $\\mathbf{U}$ will represent users, we need to take the transposition of $\\mathbf{V}$ for the matrix multiplication to be valid.\n",
    "\n",
    "What is the benefit of this factorization? Just as how neural networks can <i>learn</i> features given data, this matrix factorization will also learn features (as I will soon show).\n",
    "\n",
    "We will see that each column in $\\mathbf{V}$ represents an automatically learned feature. And each row in $\\mathbf{U}$ is the linear strength of that feature for predicting a users preference to an item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function\n",
    "\n",
    "So how do learn what the values of $\\mathbf{U}$ and $\\mathbf{V}$ are? We determine this via a cost function. A simple idea is, is to multiple the matrices $\\mathbf{U}$ and $\\mathbf{V}$ (starting from some initial values) and multiply them. Then, we can compare how close the values of $\\mathbf{U}\\mathbf{V}^{\\text{T}}$ match the known $\\mathbf{R_{m \\times n}}$ matrix.  We compare using the squared error. We also introduce regularization to mitigate overfitting. Our cost function is the following:\n",
    "\n",
    "$J(\\mathbf{U}, \\mathbf{V}) = \\frac{1}{2}||\\mathbf{R} - \\mathbf{U}\\mathbf{V}^{\\text{T}}||^2 + \\lambda_u ||\\mathbf{U}||^2 +  \\lambda_v ||\\mathbf{V}||^2$\n",
    "\n",
    "We can also write this out explicitly:\n",
    "\n",
    "$J(\\mathbf{U}, \\mathbf{V}) = \\sum_{i=1}^{m} \\sum_{j=1}^{n} (\\mathbf{R}_{ij} - \\sum_{k=1}^{K} \\mathbf{U}_{ik} \\mathbf{V}_{jk})^{2} + \\lambda_u \\sum_{i=1}^{n} \\sum_{k=1}^{K} \\mathbf{U}_{ik}^2 + \\lambda_v \\sum_{j=1}^{n} \\sum_{k=1}^{K} \\mathbf{V}_{jk}^2$\n",
    "\n",
    "\n",
    "In practice, not all entries in $\\mathbf{R}$ are defined. So what do we do? This is equivalent to not having training examples, so we can just skip these entries. Later on our derivation, I show this is equivalent to setting the missing entries to 0.\n",
    "\n",
    "The $\\mathbf{U}_{ik} \\mathbf{V}_{jk}$ term makes this function non-convex (i.e., no one global minimum). This is where a few assumptions are made to make the problem tractable. First, we hold $\\mathbf{V}$ constant while optimizing over $\\mathbf{U}$. Then, we hold $\\mathbf{U}$ constant while optimizing over $\\mathbf{V}$. We repeat this alternation until convergence. Hence, <i>alternating least squares</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U\n",
    "To calculate $\\mathbf{U}$, we first initialize the parameters in the matrix to small random values. We then treat $\\mathbf{V}$ as fixed. Next, we break solving each $\\mathbf{U}_i$ row into $m$ independent equations to solve.\n",
    "\n",
    "Let's examine the ith row:\n",
    "\n",
    "$J(\\mathbf{U}_{i1}, \\mathbf{U}_{i2}, ..., \\mathbf{U}_{ik}; \\mathbf{V}) = \\sum_{j}^{n} (\\mathbf{R}_{ij} - \\sum_{k=1}^{K} \\mathbf{U}_{ik} \\mathbf{V}_{jk})^{2} + \\lambda_u \\sum_{k=1}^{K} \\mathbf{U}_{ik}^2$\n",
    "\n",
    "Let's recast the equation into its matrix form:\n",
    "\n",
    "$J(\\mathbf{U}_{i,*}) = (\\mathbf{R}_{i,*} - \\mathbf{U}_{i,*} \\mathbf{V}^{\\text{T}}) (\\mathbf{R}_{i,*} - \\mathbf{U}_{i,*} \\mathbf{V}^{\\text{T}})^{\\text{T}}  + \\lambda_u \\mathbf{U}_{i,*} ({\\mathbf{U}_{i,*}})^{\\text{T}}$\n",
    "\n",
    "Let's check our dimensions are valid:\n",
    "\n",
    "$(1 \\times 1) = (1 \\times n - (1 \\times k)(k \\times n)) \\;  (1 \\times n - (1 \\times k)(k \\times n))^T + (1 \\times k)(k \\times 1)$\n",
    "\n",
    "\n",
    "### Theoretical Insight\n",
    "\n",
    "Now, some theoretical insight. Let's exploit a property of transposition (e.g., $(\\mathbf{A}^{\\text{T}}\\mathbf{B})^{\\text{T}} = \\mathbf{B}^T\\mathbf{A}$) to get:\n",
    "\n",
    "$J(\\mathbf{U}_{i,*}) = ((\\mathbf{R}_{i,*})^{\\text{T}} - \\mathbf{V} (\\mathbf{U}_{i,*})^{\\text{T}})^{\\text{T}} (\\mathbf{R}_{i,*}^{\\text{T}} - \\mathbf{V} (\\mathbf{U}_{i,*})^T)  + \\lambda_u \\mathbf{U}_{i,*} \\mathbf{U}_{i,*}^{\\text{T}}$\n",
    "\n",
    "We can rename these variables and matrices. Let:\n",
    "\n",
    "$\\mathbf{y} \\equiv (\\mathbf{R}_{i,*})^T$\n",
    "\n",
    "$\\mathbf{X} \\equiv \\mathbf{V}$\n",
    "\n",
    "$\\beta \\equiv (\\mathbf{U}_{i,*})^T$\n",
    "\n",
    "$\\lambda \\equiv \\lambda_u$\n",
    "\n",
    "This yields:\n",
    "\n",
    "$J(\\mathbf{\\beta}) = (\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta)  + \\lambda \\beta^T \\beta$\n",
    "\n",
    "\n",
    "This is the equation for Ridge regression (also known as Tikhonov regularization).\n",
    "\n",
    "\n",
    "### X, y\n",
    "In Ridge regression, $\\mathbf{X}$ is the design matrix where each row is a training example and each column is a feature. Each row in $\\mathbf{X}$ corresponds to an entry in the column vector $\\mathbf{y}$. $\\mathbf{y}$ is the response variable, that is, the outcome we are trying to predict given features.\n",
    "\n",
    "For ALS, each outcome is the preference of a given user to a given item. And each row in $\\mathbf{V}$ is a training example where each column is a feature. There are $k$ features. But wait, we never created the features! These features are in fact, learned from data. We call these features <i>latent</i> features for this reason. Latent means \"hidden\".\n",
    "\n",
    "### $\\beta$\n",
    "And what is $\\beta$? In linear regression, this is the linear relationship of each feature to the response variable $\\mathbf{y}$. So the ith row of $\\mathbf{U}$ represents the coefficients. If the number is 0 for example, there exists no linear relationship (this confirmation is decided by statistical significance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "Our problem is now to solve the problem of Ridge regression. We want to minimize the following cost function:\n",
    "\n",
    "$J(\\beta) = (\\mathbf{y} - \\mathbf{X} \\beta)^{\\text{T}} (\\mathbf{y} - \\mathbf{X} \\beta)  + \\lambda \\beta^{\\text{T}} \\beta$\n",
    "\n",
    "Let's expand our cost function:\n",
    "\n",
    "$J(\\beta) = \\mathbf{y}\\mathbf{y}^{\\text{T}} - \\mathbf{y}^{\\text{T}} \\mathbf{X} \\beta - (\\mathbf{X} \\beta)^{\\text{T}} \\mathbf{y} + (\\mathbf{X}\\beta)^{\\text{T}} \\mathbf{X} \\beta + \\lambda \\beta^{\\text{T}} \\beta$\n",
    "\n",
    "Note that $(\\mathbf{X} \\beta)^{\\text{T}} \\mathbf{y}$ is a scalar, and so a transpose of a scalar is itself. Thus $(\\mathbf{X} \\beta)^{\\text{T}} \\mathbf{y} = \\mathbf{y}^{\\text{T}} \\mathbf{X} \\beta$. We also simplify $(\\mathbf{X}\\beta)^T \\mathbf{X} \\beta$ to $\\beta^{\\text{T}} \\mathbf{X}^T \\mathbf{X} \\beta$ This gives us the following:\n",
    "\n",
    "$J(\\beta) = \\mathbf{y}\\mathbf{y}^T - 2 \\mathbf{y}^{\\text{T}} \\mathbf{X} \\beta + \\beta^{\\text{T}} \\mathbf{X}^{\\text{T}} \\mathbf{X} \\beta + \\lambda \\beta^{\\text{T}} \\beta$\n",
    "\n",
    "We now use matrix calculus to take the derivative with respect to the column vector $\\beta$. We set this derivative equal to 0 (this locates a minimum, maximum, or an inflection point). This yields:\n",
    "\n",
    "\n",
    "$\\frac{\\partial{J}}{{\\partial \\beta}} = -2\\mathbf{y}^{\\text{T}} \\mathbf{X} + \\frac{\\partial{(\\beta^{\\text{T}} \\mathbf{X}^{\\text{T}} \\mathbf{X} \\beta)}}{{\\partial \\beta}} +  2 \\lambda \\beta^{\\text{T}} = 0$\n",
    "\n",
    "\n",
    "Note that $\\mathbf{X}^{\\text{T}} \\mathbf{X}$ is a symmetric matrix. We can use the following property (see proposition 9 in https://atmos.washington.edu/~dennis/MatrixCalculus.pdf):\n",
    "\n",
    "$\\alpha = \\mathbf{x}^{\\text{T}} \\textbf{A} \\textbf{x} \\implies \\frac{\\partial \\alpha}{\\partial \\mathbf{x}} = 2 \\textbf{x}^{\\text{T}} \\textbf{A}$\n",
    "\n",
    "So now we get:\n",
    "\n",
    "$-2y^{\\text{T}} \\mathbf{X} + 2\\beta^{\\text{T}} \\mathbf{X}^{\\text{T}} \\mathbf{X} +  2 \\lambda \\beta^{\\text{T}} = 0$\n",
    "\n",
    "rearranging and dividing by $2$ throughout we get:\n",
    "\n",
    "$y^{\\text{T}} \\mathbf{X} = \\beta^{\\text{T}} X^{\\text{T}} \\mathbf{X} + \\lambda \\beta^{\\text{T}}$\n",
    "\n",
    "Factoring out $\\beta$:\n",
    "\n",
    "$y^{\\text{T}} \\mathbf{X} = \\beta^{\\text{T}} (X^{\\text{T}} \\mathbf{X} + \\lambda I)$\n",
    "\n",
    "Taking inverse:\n",
    "\n",
    "$y^{\\text{T}} \\mathbf{X} (\\mathbf{X}^{\\text{T}} \\mathbf{X} + \\lambda I)^{-1} = \\beta^{\\text{T}}$\n",
    "\n",
    "Taking tranpose:\n",
    "\n",
    "$\\beta = (\\mathbf{X}^{\\text{T}} \\mathbf{X} + \\lambda I)^{-1} \\mathbf{X}^{\\text{T}} \\mathbf{y} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating U Matrix\n",
    "\n",
    "We now know the solution for:\n",
    "\n",
    "$J(\\beta) = (\\mathbf{y} - \\mathbf{X} \\beta)^{\\text{T}} (\\mathbf{y} - \\mathbf{X} \\beta)  + \\lambda \\beta^{\\text{T}} \\beta$\n",
    "\n",
    "is\n",
    "\n",
    "$\\beta = (\\mathbf{X}^{\\text{T}} \\mathbf{X} + \\lambda \\mathbf{I})^{-1} \\mathbf{X}^{\\text{T}} \\mathbf{y} $\n",
    "\n",
    "Going back to our original equation\n",
    "\n",
    "$J(\\mathbf{U}_{i,*}) = ((\\mathbf{R}_{i,*})^{\\text{T}} - \\mathbf{V} (\\mathbf{U}_{i,*})^{\\text{T}})^{\\text{T}} ((\\mathbf{R}_{i,*})^{\\text{T}} - \\mathbf{V} (\\mathbf{U}_{i,*})^T)^{\\text{T}}  + \\lambda_u \\mathbf{U}_{i,*} (\\mathbf{U}_{i,*})^{\\text{T}}$\n",
    "\n",
    "We can just match up our vectors/matrices to get:\n",
    "\n",
    "$(\\mathbf{U}_{i,*})^{\\text{T}} = (\\mathbf{V}^{\\text{T}} \\mathbf{V} + \\lambda_u \\mathbf{I})^{-1} \\mathbf{V}^{\\text{T}} (\\mathbf{R}_i)^T $\n",
    "\n",
    "or traking tranpose:\n",
    "\n",
    "$\\mathbf{U}_{i,*} = \\mathbf{R}_{i,*} \\mathbf{V} (\\mathbf{V}^{\\text{T}} \\mathbf{V} + \\lambda_u \\mathbf{I})^{-1}$\n",
    "\n",
    "\n",
    "# Updating V Matrix\n",
    "\n",
    "What about $\\mathbf{V}_{j,*}$? The cost function for this in matrix form is:\n",
    "\n",
    "$J(\\mathbf{V}_{j,*}) = ((\\mathbf{R}^{\\text{T}})_{j,*} - \\mathbf{V}_{j,*} \\mathbf{U}^{\\text{T}})(((\\mathbf{R}^{\\text{T}})_{j,*} - \\mathbf{V}_{j,*} \\mathbf{U}^{\\text{T}})^{\\text{T}} + \\lambda_v \\mathbf{V}_{j,*} (\\mathbf{V}_{j,*})^{\\text{T}}$\n",
    "\n",
    "or\n",
    "\n",
    "$J(\\mathbf{V}_{j,*}) = (\\mathbf{R}_{*,j} - \\mathbf{U} (\\mathbf{V}_{j,*})^{\\text{T}})^{\\text{T}} (\\mathbf{R}_{*,j} - \\mathbf{U} (\\mathbf{V}_{j,*})^{\\text{T}}) + \\lambda_v \\mathbf{V}_{j,*} (\\mathbf{V}_{j,*})^{\\text{T}}$\n",
    "\n",
    "Let's check our dimensions are valid:\n",
    "\n",
    "$(1 \\times 1) = (m \\times 1 - (m \\times k)(k \\times 1))^{\\text{T}} \\;  (m \\times 1 - (m \\times k)(1 \\times k)^{\\text{T}}) + (1 \\times k)(k \\times 1)$\n",
    "\n",
    "Again, comparing to solution for Ridge regression we just match up terms:\n",
    "\n",
    "$(\\mathbf{V}_{j,*})^{\\text{T}} = (\\mathbf{U}^{\\text{T}} \\mathbf{U} + \\lambda_v \\mathbf{I})^{-1} \\mathbf{U}^{\\text{T}} \\mathbf{R}_{*,j}$\n",
    "\n",
    "or\n",
    "\n",
    "$\\mathbf{V}_{j,*} = ((\\mathbf{R}^{\\text{T}})_{j,*} \\mathbf{U} (\\mathbf{U}^{\\text{T}} \\mathbf{U} + \\lambda_v I)^{-1}$\n",
    "\n",
    "# Summary\n",
    "\n",
    "For each ith row in $\\mathbf{U}$:\n",
    "\n",
    "$\\mathbf{U}_{i,*} = \\mathbf{R}_{i,*} \\mathbf{V} (\\mathbf{V}^{\\text{T}} \\mathbf{V} + \\lambda_u \\mathbf{I})^{-1}$\n",
    "\n",
    "For each jth row in $\\mathbf{V}$:\n",
    "\n",
    "$\\mathbf{V}_{j,*} = ((\\mathbf{R}^{\\text{T}})_{j,*} \\mathbf{U} (\\mathbf{U}^{\\text{T}} \\mathbf{U} + \\lambda_v I)^{-1}$\n",
    "\n",
    "For each ith row in $\\mathbf{U}$:\n",
    "\n",
    "$\\mathbf{U}_{i,*} = \\mathbf{R}_{i,*} \\mathbf{V} (\\mathbf{V}^{\\text{T}} \\mathbf{V} + \\lambda_u \\mathbf{I})^{-1}$\n",
    " \n",
    "and so on ....\n",
    "\n",
    "## Missing Entries\n",
    "\n",
    "But what do we do when entries in $\\mathbf{R}$ are undefined? Suppose we skip over these. Let's examine this term: $\\mathbf{R}_{i,*} \\mathbf{V}$. This computes $k$ dot products where each dot product is the ith row of $\\mathbf{R}$ dotted with each column in $\\mathbf{V}$. If we skip the missing entries in $\\mathbf{R}$, this is equivalent to setting the missing entry in $\\mathbf{R}$ to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "We've performed the mathematical analysis, now let's implement this using Python. First, we import all of the libraries we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class below, implements the math we developed. We use sklearn's implementation of Ridge regression instead of rolling our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomALS(object):\n",
    "    \"\"\"Predicts using ALS\"\"\"\n",
    "    \n",
    "    def __init__(self, k=20, n_iter=20, lambda_u=0.001,\n",
    "                 lambda_v=0.001):\n",
    "        \n",
    "        self.k = k\n",
    "        self.n_iter = 20\n",
    "        self.lambda_u = lambda_u\n",
    "        self.lambda_v = lambda_v\n",
    "                                   \n",
    "    def fit(self, R):\n",
    "        self.R = R.copy()\n",
    "        \n",
    "        # Convert missing entries to 0\n",
    "        self.R = np.nan_to_num(self.R)\n",
    "            \n",
    "        m, n = R.shape\n",
    "  \n",
    "        # Initialize\n",
    "        self.U = np.random.normal(loc=0., scale=0.01, size=(m, self.k))\n",
    "        self.V = np.random.normal(loc=0., scale=0.01, size=(n, self.k))\n",
    "\n",
    "        I = np.eye(self.k)\n",
    "        Iu = self.lambda_u * I\n",
    "        Iv = self.lambda_v * I\n",
    "        \n",
    "        R_T = self.R.T\n",
    "        \n",
    "        model_u = Ridge(alpha=self.lambda_u,\n",
    "                        fit_intercept=True,\n",
    "                        normalize=True)\n",
    "        \n",
    "        model_v = Ridge(alpha=self.lambda_v,\n",
    "                        fit_intercept=True,\n",
    "                        normalize=True)\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            # NOTE: This can be parallelized\n",
    "            for i in range(m):\n",
    "                model_u.fit(X=self.V,\n",
    "                            y=R_T[:,i])       \n",
    "                self.U[i,:] = model_u.coef_\n",
    "                \n",
    "            # NOTE: This can be parallelized\n",
    "            for j in range(n):\n",
    "                model_v.fit(X=self.U,\n",
    "                            y=R_T[j,:])        \n",
    "                self.V[j,:] = model_v.coef_\n",
    "\n",
    "        self.R_hat = self.U.dot(self.V.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we also construct a version that uses Apache Spark's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"test\") \\\n",
    "        .getOrCreate()\n",
    "        \n",
    "class SparkALS(object):\n",
    "    def __init__(self, k=20, n_iter=20, lambda_=0.001):   \n",
    "        self.als = ALS(rank=k, maxIter=n_iter, regParam=lambda_)\n",
    "    \n",
    "    def fit(self, R):\n",
    "        R = np.nan_to_num(R)\n",
    "        ratings = []\n",
    "        for i in range(R.shape[0]):\n",
    "            for j in range(R.shape[1]):\n",
    "                ratings.append((i, j, float(R[i,j])))\n",
    "\n",
    "        df = spark.createDataFrame(ratings,\n",
    "                                   [\"user\", \"item\", \"rating\"])\n",
    "        \n",
    "        model = self.als.fit(df)\n",
    "        \n",
    "        user_factors = model.userFactors.orderBy(\"id\").collect()\n",
    "        item_factors = model.itemFactors.orderBy(\"id\").collect()\n",
    "        \n",
    "        self.U = np.array([f.features for f in user_factors])\n",
    "        self.V = np.array([f.features for f in item_factors])\n",
    "        self.R_hat = self.U.dot(self.V.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how well did we do? We leverage the MovieLens dataset test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.read_csv('../ml-latest-small/ratings.csv')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>161084</th>\n",
       "      <th>161155</th>\n",
       "      <th>161594</th>\n",
       "      <th>161830</th>\n",
       "      <th>161918</th>\n",
       "      <th>161944</th>\n",
       "      <th>162376</th>\n",
       "      <th>162542</th>\n",
       "      <th>162672</th>\n",
       "      <th>163949</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9066 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "1           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           NaN     NaN     4.0     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  9       10       ...    161084  161155  161594  161830  161918  \\\n",
       "userId                    ...                                             \n",
       "1           NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "2           NaN     4.0   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     4.0   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "5           NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  161944  162376  162542  162672  163949  \n",
       "userId                                           \n",
       "1           NaN     NaN     NaN     NaN     NaN  \n",
       "2           NaN     NaN     NaN     NaN     NaN  \n",
       "3           NaN     NaN     NaN     NaN     NaN  \n",
       "4           NaN     NaN     NaN     NaN     NaN  \n",
       "5           NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 9066 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df = df_ratings.pivot(index='userId',\n",
    "                        columns='movieId',\n",
    "                        values='rating'\n",
    "                       ).fillna(np.nan)\n",
    "R_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decriptive Stats of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: (671, 9066)\n",
      "Density: 0.02\n",
      "Sparsity: 0.98\n",
      "# Ratings / User: 149.04 +/- 231.05\n"
     ]
    }
   ],
   "source": [
    "# Size\n",
    "print('Size: {}'.format(R_df.shape))\n",
    "\n",
    "# What is the density of this matrix?\n",
    "num_entries = np.count_nonzero(~np.isnan(R_df))\n",
    "N = R_df.shape[0] * R_df.shape[1]\n",
    "density = round(num_entries / N, 2)\n",
    "sparsity = 1. - density\n",
    "print('Density: {}'.format(density))\n",
    "print('Sparsity: {}'.format(sparsity))\n",
    "\n",
    "# How many non-nans on average, per row?\n",
    "c = np.count_nonzero(~np.isnan(R_df), axis=1)\n",
    "print('# Ratings / User: {} +/- {}'.format(round(c.mean(), 2), round(c.std(), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10841e240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution\n",
    "plt.hist(c, bins=100)\n",
    "plt.title('Distribution of #Ratings/User')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Number of non-missing ratings per user')\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Who the rated over 2,000 movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>161084</th>\n",
       "      <th>161155</th>\n",
       "      <th>161594</th>\n",
       "      <th>161830</th>\n",
       "      <th>161918</th>\n",
       "      <th>161944</th>\n",
       "      <th>162376</th>\n",
       "      <th>162542</th>\n",
       "      <th>162672</th>\n",
       "      <th>163949</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 9066 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "547         3.5     NaN     NaN     NaN     NaN     2.5     2.0     NaN   \n",
       "\n",
       "movieId  9       10       ...    161084  161155  161594  161830  161918  \\\n",
       "userId                    ...                                             \n",
       "547         NaN     NaN   ...       2.5     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  161944  162376  162542  162672  163949  \n",
       "userId                                           \n",
       "547         NaN     NaN     NaN     NaN     5.0  \n",
       "\n",
       "[1 rows x 9066 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_df[R_df.count(axis=1) > 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently user 547..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an evaluation metric to determine how well our algorithm performs. Classically in recommender systems, the RMSE (root mean squared error) is used. But we don't really care on predicting the absolute rating, but rather, did we rank the items correctly? A metric that captures this, is NDCG (normalized discounted cumulative gain)--developed by Kalervo Järvelin and Jaana Kekäläinen in the paper <b>IR evaluation methods for retrieving highly relevant documents</b>.\n",
    "\n",
    "NDCG can be broken down into 4 distinct concepts:\n",
    "\n",
    "<b>N</b> = <i>normalized</i>\n",
    "\n",
    "<b>D</b> = discounted\n",
    "\n",
    "<b>C</b> = cumulative\n",
    "\n",
    "<b>G</b> = gain\n",
    "\n",
    "Let's start with gain. Gain is the relevance value of the item. But now, suppose we look at the top $k$ items ranked. We can sum the gain of each item. This is the <i>cumulative</i> part. Thus:\n",
    "\n",
    "$\\text{CG} = \\sum_i^k G_i$\n",
    "\n",
    "But, suppose we were to shuffle the order of the items in the top $k$. The CG value is not affected since the gain is not a function of position. So what we do, is multiply by a discounting factor that <i>is</i> a function of position:\n",
    "\n",
    "$D(i) = \\frac{1}{log_2(i + 1)}$\n",
    "\n",
    "We examine its multiplicative effect by plotting it for first 20 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107baa978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.arange(1, 20)\n",
    "plt.title(\"Discounting Factor\")\n",
    "plt.ylim([0., 1.])\n",
    "plt.xticks(i)\n",
    "plt.ylabel('D(i)')\n",
    "plt.xlabel('Rank')\n",
    "plt.plot(i, (lambda x: 1. / np.log2(x + 1))(i), marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the <i>normalized</i> part ensures that our metric is bounded between 0 and 1. To normalize, you just have to arrange the items in the top $k$ such that the max DCG value is obtained. But, this max DCG value considers all of the items, not just the ones filtered in top $k$. So as an example, suppose the true ordering of items rated by relevancy is:\n",
    "\n",
    "[6, 4, 3, 2, 1]\n",
    "\n",
    "But in our top k=3, we have:\n",
    "\n",
    "[4, 3, 2]\n",
    "\n",
    "But the true best top k=3 is actually:\n",
    "\n",
    "[6, 4, 3]\n",
    "\n",
    "\n",
    "So the DCG value of [6, 4, 3] is the max score. This is the constant we should divide by. We'll refer to this as IDCG (ideal discounted cumulative gain). So finally, our equation is as follows:\n",
    "\n",
    "\n",
    "$NDCG = \\frac{1}{IDCG} \\sum_i^k \\frac{G_i}{log_2(i + 1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can implement NDCG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(x, k):\n",
    "    \n",
    "    if k == 0:\n",
    "        return .0\n",
    "    elif k < 0:\n",
    "        raise ValueError('k cannot be negative')\n",
    "            \n",
    "    # 1, 2, ..., k\n",
    "    i = np.arange(1, k + 1)\n",
    "    \n",
    "    # Discount factor\n",
    "    d = 1. / np.log2(i + 1)\n",
    "    \n",
    "    # Sorted for best possible scores\n",
    "    x_best = np.sort(x)[::-1]\n",
    "        \n",
    "    # Compute normalization constant\n",
    "    N = np.sum(d * x_best[:k])\n",
    "    n = np.sum(d * x[:k])\n",
    "    \n",
    "    return n / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we are almost ready to test the models. Here's how this will work. We will run k fold cross validation on our dataset. By default, we will split our matrix into two parts. We will train on the first, then test on the second. Then train on the second, and test on the first. But what are we testing? In our test set, for a given user, we will perform stratified sampling. Our stratas are: ratings and missing ratings. From these stratas, we will allow the training to get access to half of each. Then during evaluation, we will select the test portions of the stratas, and examine how well we did via NDCG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_ndcg(model, X, n_splits=2):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    rows = list(range(m))\n",
    "    \n",
    "    # Row index\n",
    "    I = np.array(range(n))\n",
    "        \n",
    "    # Now, split into K folds (by users)\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    scores = []\n",
    "    for train, test in kf.split(rows):\n",
    "        \n",
    "        # Assign test entries as undefined\n",
    "        X_train = X.copy()\n",
    "        X_test = X[test,:]\n",
    "        \n",
    "        user_indx = dict()\n",
    "        \n",
    "        # Prepare training set\n",
    "        for i in test:            \n",
    "            # Indices with non-nan\n",
    "            pos_indx = I[~np.isnan(X[i,:])]\n",
    "            neg_indx = I[np.isnan(X[i,:])]\n",
    "            \n",
    "            # Shuffle indices\n",
    "            np.random.shuffle(pos_indx)\n",
    "            np.random.shuffle(neg_indx)\n",
    "                    \n",
    "            pos_test, _ = np.array_split(pos_indx, 2)\n",
    "            neg_test, _ = np.array_split(neg_indx, 2)\n",
    "       \n",
    "            test_indx = np.append(pos_test, neg_test)\n",
    "            \n",
    "            # \"Hide\" entries for this person\n",
    "            X_train[i, pos_test] = np.nan\n",
    "            \n",
    "            # Remember what indices to\n",
    "            # use during testing\n",
    "            user_indx[i] = test_indx\n",
    "        \n",
    "        # Train\n",
    "        model.fit(X_train)\n",
    "        \n",
    "        R_hat = model.R_hat\n",
    "        \n",
    "        for i in test:\n",
    "            test_indx = user_indx[i]\n",
    "            \n",
    "            # Need to rank these\n",
    "            # according to our algorithm\n",
    "            values = X[i, test_indx]\n",
    "            \n",
    "            # Replace missing entries with 0\n",
    "            I_ = np.array(range(len(values)))\n",
    "            neg_indx = I_[np.isnan(values)]\n",
    "            values[neg_indx] = 0.\n",
    "            \n",
    "            # These are the predicted values\n",
    "            pred = R_hat[i, test_indx]\n",
    "            \n",
    "            # Get sorted index position\n",
    "            sort_indx = np.argsort(pred)[::-1]\n",
    "            \n",
    "            values = values[sort_indx]\n",
    "            \n",
    "            # Now, order pred by holdout values\n",
    "            ndcg = ndcg_at_k(values, k=20)\n",
    "                    \n",
    "            scores.append(ndcg)\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_scores = cross_val_ndcg(CustomALS(), R_df.values, n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_als_scores = cross_val_ndcg(SparkALS(), R_df.values, n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [{'scores': als_scores, 'name': 'als', 'color': 'blue'},\n",
    "          {'scores': spark_als_scores, 'name': 'spark-als', 'color': 'red'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x106f4f630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106f4fdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for v in scores:\n",
    "    mu = round(np.mean(v['scores']),2)\n",
    "    std = round(np.std(v['scores']),2)\n",
    "    \n",
    "    plt.hist(v['scores'], color=v['color'],\n",
    "             bins=50, alpha=0.4,\n",
    "             label='{}, $\\mu$={}, $\\sigma$={}'.format(v['name'], mu, std))\n",
    "\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('NDCG@20')\n",
    "plt.title('2 Fold Cross Validation')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see the implmentations are similar. But this arises from the fact because we now <i>understand</i> how ALS works. Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
